[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Practicals",
    "section": "",
    "text": "This is a Quarto website to display my practicals.\nHere is the link to my GitHub repository: https://github.com/Dominique-Chetty/Statistical-Computing-Practicals :)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "PracticalOne.html",
    "href": "PracticalOne.html",
    "title": "Practical One",
    "section": "",
    "text": "Code\naq_data &lt;- airquality\n\n#Counts how many rows have any column with an NA value\nprint(\"Number of rows with NA values\")\n\n\n[1] \"Number of rows with NA values\"\n\n\nCode\nsum(rowSums(is.na(aq_data)) &gt; 0)\n\n\n[1] 42\n\n\nCode\n#Find the location of missing values\nprint(\"Position of the missing values\")\n\n\n[1] \"Position of the missing values\"\n\n\nCode\nwhich(is.na(aq_data))\n\n\n [1]   5  10  25  26  27  32  33  34  35  36  37  39  42  43  45  46  52  53  54\n[20]  55  56  57  58  59  60  61  65  72  75  83  84 102 103 107 115 119 150 158\n[39] 159 164 180 249 250 251\n\n\nCode\n# count total missing values \nprint(\"Count of total missing values  \")\n\n\n[1] \"Count of total missing values  \"\n\n\nCode\nsum(is.na(aq_data))\n\n\n[1] 44"
  },
  {
    "objectID": "PracticalOne.html#question-1",
    "href": "PracticalOne.html#question-1",
    "title": "Practical One",
    "section": "",
    "text": "Code\naq_data &lt;- airquality\n\n#Counts how many rows have any column with an NA value\nprint(\"Number of rows with NA values\")\n\n\n[1] \"Number of rows with NA values\"\n\n\nCode\nsum(rowSums(is.na(aq_data)) &gt; 0)\n\n\n[1] 42\n\n\nCode\n#Find the location of missing values\nprint(\"Position of the missing values\")\n\n\n[1] \"Position of the missing values\"\n\n\nCode\nwhich(is.na(aq_data))\n\n\n [1]   5  10  25  26  27  32  33  34  35  36  37  39  42  43  45  46  52  53  54\n[20]  55  56  57  58  59  60  61  65  72  75  83  84 102 103 107 115 119 150 158\n[39] 159 164 180 249 250 251\n\n\nCode\n# count total missing values \nprint(\"Count of total missing values  \")\n\n\n[1] \"Count of total missing values  \"\n\n\nCode\nsum(is.na(aq_data))\n\n\n[1] 44"
  },
  {
    "objectID": "PracticalOne.html#question-2",
    "href": "PracticalOne.html#question-2",
    "title": "Practical One",
    "section": "Question 2",
    "text": "Question 2\n\nFind mean, sd, min, max for each of temperature and ozone level.\n\n\nCode\n#Find the mean of Temperature\nprint(\"The mean temperature is:\")\n\n\n[1] \"The mean temperature is:\"\n\n\nCode\nmean(aq_data$Temp)\n\n\n[1] 77.88235\n\n\nCode\n#Find the sd of Temperature\nprint(\"The standard deviation of temperature is:\")\n\n\n[1] \"The standard deviation of temperature is:\"\n\n\nCode\nsd(aq_data$Temp)\n\n\n[1] 9.46527\n\n\nCode\n#Find the min Temperature\nprint(\"The minimum temperature is:\")\n\n\n[1] \"The minimum temperature is:\"\n\n\nCode\nmin(aq_data$Temp)\n\n\n[1] 56\n\n\nCode\n#Find the max Temperature\nprint(\"The maximum temperature is:\")\n\n\n[1] \"The maximum temperature is:\"\n\n\nCode\nmax(aq_data$Temp)\n\n\n[1] 97\n\n\nCode\n#############################################\n\n#Find the mean of ozone level\nprint(\"The mean ozone level is:\")\n\n\n[1] \"The mean ozone level is:\"\n\n\nCode\nmean(aq_data$Ozone, na.rm = TRUE)\n\n\n[1] 42.12931\n\n\nCode\n#Find the sd of ozone level\nprint(\"The standard deviation of ozone level is:\")\n\n\n[1] \"The standard deviation of ozone level is:\"\n\n\nCode\nsd(aq_data$Ozone, na.rm = TRUE)\n\n\n[1] 32.98788\n\n\nCode\n#Find the min ozone level\nprint(\"The minimum ozone level is:\")\n\n\n[1] \"The minimum ozone level is:\"\n\n\nCode\nmin(aq_data$Ozone, na.rm = TRUE)\n\n\n[1] 1\n\n\nCode\n#Find the max ozone level\nprint(\"The maximum ozone level is:\")\n\n\n[1] \"The maximum ozone level is:\"\n\n\nCode\nmax(aq_data$Ozone, na.rm = TRUE)\n\n\n[1] 168"
  },
  {
    "objectID": "PracticalOne.html#question-3",
    "href": "PracticalOne.html#question-3",
    "title": "Practical One",
    "section": "Question 3",
    "text": "Question 3\n\nFit a simple linear regression model to the car data, i.e. find the β estimates, using the parameter estimate equation for linear regression, and matrix calculations.\n\n\nCode\ncars_data &lt;- cars\n\n# Create the x variable vector for speed\nx &lt;- cbind(1, cars_data$speed)\n\n# Create the y variable vector for distance\ny &lt;- as.matrix(cars_data$dist)\n\n# Calculate the Beta parameter estimate\nbeta_hat &lt;- solve(t(x) %*% x)  %*%  t(x) %*% y\nprint(\"The parameter estimates from the matrix calculation is:\")\n\n\n[1] \"The parameter estimates from the matrix calculation is:\"\n\n\nCode\nbeta_hat\n\n\n           [,1]\n[1,] -17.579095\n[2,]   3.932409"
  },
  {
    "objectID": "PracticalOne.html#question-4",
    "href": "PracticalOne.html#question-4",
    "title": "Practical One",
    "section": "Question 4",
    "text": "Question 4\n\nCheck that you get the same  β estimates as when fitting the linear regression model using lm()\n\n\nCode\n# linear regression model of the cars dataset \nlm_model &lt;-  lm(dist ~ speed, data = cars)\n\n#Get the Beta estimate\nprint(\"The parameter estimates from the linear regression model is:\")\n\n\n[1] \"The parameter estimates from the linear regression model is:\"\n\n\nCode\ncoef(lm_model)\n\n\n(Intercept)       speed \n -17.579095    3.932409 \n\n\n\n\nExtra:\nCreate a function to calculate the beta, standard error and t-value of the linear regression model\n\n\nCode\nstats &lt;- function(x, y) {\n  n &lt;- length(y)\n  X &lt;- cbind(1, x)  # adds the intercept term\n  beta_hat &lt;- solve(t(X) %*% X) %*% (t(X) %*% y)  # calc the beta coefficient from X and y vectors\n  \n  y_hat &lt;- X %*% beta_hat\n  residuals &lt;- y - y_hat\n  sigma_sq &lt;- sum(residuals^2) / (n - 2)  # calculates the variance \n  \n  var_beta &lt;- sigma_sq * solve(t(X) %*% X)  # calculates the variance-covariance matrix\n  std_error &lt;- sqrt(diag(var_beta))  #  calculates the standard error of coefficients\n  \n  t_values &lt;- beta_hat / std_error  # calculate the t-values\n  \n  return(list(beta = beta_hat[2], std_error = std_error[2], t_value = t_values[2]))\n}\n\n\nApply the stats function to the dependent and independent variables of the cars data set\n\n\nCode\nstats(cars$speed, cars$dist)\n\n\n$beta\n[1] 3.932409\n\n$std_error\n        x \n0.4155128 \n\n$t_value\n[1] 9.46399\n\n\nCompare the above calculated statistics to the pre-coded statistics for an lm function\n\n\nCode\nsummary(lm_model)\n\n\n\nCall:\nlm(formula = dist ~ speed, data = cars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-29.069  -9.525  -2.272   9.215  43.201 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -17.5791     6.7584  -2.601   0.0123 *  \nspeed         3.9324     0.4155   9.464 1.49e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15.38 on 48 degrees of freedom\nMultiple R-squared:  0.6511,    Adjusted R-squared:  0.6438 \nF-statistic: 89.57 on 1 and 48 DF,  p-value: 1.49e-12"
  },
  {
    "objectID": "PracticalTwo.html",
    "href": "PracticalTwo.html",
    "title": "Practical Two",
    "section": "",
    "text": "# set the seed to create reproducable results\nset.seed(1)\n\n# create x as a sequence of numbers from 1 to 100\nx &lt;- 1:100\n\n# Generate y as a noisy sine wave such that yi=sin(xi/10)+ei where ei∼N(0,0.22)\ne &lt;- rnorm(100, mea = 0, sd = 0.2)\n\ny &lt;- sin(x/10) + e"
  },
  {
    "objectID": "PracticalTwo.html#generate-simulated-data",
    "href": "PracticalTwo.html#generate-simulated-data",
    "title": "Practical Two",
    "section": "",
    "text": "# set the seed to create reproducable results\nset.seed(1)\n\n# create x as a sequence of numbers from 1 to 100\nx &lt;- 1:100\n\n# Generate y as a noisy sine wave such that yi=sin(xi/10)+ei where ei∼N(0,0.22)\ne &lt;- rnorm(100, mea = 0, sd = 0.2)\n\ny &lt;- sin(x/10) + e"
  },
  {
    "objectID": "PracticalTwo.html#implement-the-lowess-algorithm",
    "href": "PracticalTwo.html#implement-the-lowess-algorithm",
    "title": "Practical Two",
    "section": "2. Implement the LOWESS Algorithm",
    "text": "2. Implement the LOWESS Algorithm\n\n# Define a function customLowess(x, y, f) that returns the smoothed values\n\ncustomLowess &lt;- function(x, y, f){\n  \n  y_smoothed &lt;- numeric(100) # creates a vector to store the smoothed y values\n  \n  for (i in 1:100) {\n    k &lt;- ceiling(f * 100) # Calculates the span\n    \n    # find the distances and get k nearest neighbors\n    distances &lt;- abs(x - x[i])\n    idx &lt;- order(distances)[1:k]\n    \n    # calculates the weights using the tricube kernel\n    dmax &lt;- max(distances[idx])\n    weights &lt;- (1 - (distances[idx] / dmax)^3)^3\n    weights[distances[idx] &gt;= dmax] &lt;- 0\n    \n    # perform weighted linear regression\n    X &lt;- cbind(1, x[idx])  # design matrix\n    W &lt;- diag(weights)  # Weight matrix\n    y_subset &lt;- y[idx]\n    \n    beta_hat &lt;- solve(t(X) %*% W %*% X) %*% (t(X) %*% W %*% y_subset)\n    \n    # Compute smoothed value\n    y_smoothed[i] &lt;- beta_hat[1] + beta_hat[2] * x[i]\n  }\n  \n  return(y_smoothed)\n  \n}"
  },
  {
    "objectID": "PracticalTwo.html#compare-with-rs-built-in-lowess",
    "href": "PracticalTwo.html#compare-with-rs-built-in-lowess",
    "title": "Practical Two",
    "section": "3. Compare with R’s Built-in lowess()",
    "text": "3. Compare with R’s Built-in lowess()\n\n# Use the built-in lowess() function with the same f value and plot both curves to compare their smoothing values\n\nplot(x = x, y = y, main = \"Lowess function\" )\nlines(lowess(x=x, y=y, f=0.25, iter = 0), col = \"red\") # displays the smoothed line by R's built-in function\nlines(x=x, y = customLowess(x=x, y=y, f=0.25), col = \"blue\")"
  },
  {
    "objectID": "PracticalThree.html",
    "href": "PracticalThree.html",
    "title": "Practical Three",
    "section": "",
    "text": "library(nycflights13)\n\nWarning: package 'nycflights13' was built under R version 4.3.3\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.3.3\n\n\nWarning: package 'forcats' was built under R version 4.3.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# using the flights dataset\nglimpse(flights)\n\nRows: 336,776\nColumns: 19\n$ year           &lt;int&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2…\n$ month          &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ day            &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ dep_time       &lt;int&gt; 517, 533, 542, 544, 554, 554, 555, 557, 557, 558, 558, …\n$ sched_dep_time &lt;int&gt; 515, 529, 540, 545, 600, 558, 600, 600, 600, 600, 600, …\n$ dep_delay      &lt;dbl&gt; 2, 4, 2, -1, -6, -4, -5, -3, -3, -2, -2, -2, -2, -2, -1…\n$ arr_time       &lt;int&gt; 830, 850, 923, 1004, 812, 740, 913, 709, 838, 753, 849,…\n$ sched_arr_time &lt;int&gt; 819, 830, 850, 1022, 837, 728, 854, 723, 846, 745, 851,…\n$ arr_delay      &lt;dbl&gt; 11, 20, 33, -18, -25, 12, 19, -14, -8, 8, -2, -3, 7, -1…\n$ carrier        &lt;chr&gt; \"UA\", \"UA\", \"AA\", \"B6\", \"DL\", \"UA\", \"B6\", \"EV\", \"B6\", \"…\n$ flight         &lt;int&gt; 1545, 1714, 1141, 725, 461, 1696, 507, 5708, 79, 301, 4…\n$ tailnum        &lt;chr&gt; \"N14228\", \"N24211\", \"N619AA\", \"N804JB\", \"N668DN\", \"N394…\n$ origin         &lt;chr&gt; \"EWR\", \"LGA\", \"JFK\", \"JFK\", \"LGA\", \"EWR\", \"EWR\", \"LGA\",…\n$ dest           &lt;chr&gt; \"IAH\", \"IAH\", \"MIA\", \"BQN\", \"ATL\", \"ORD\", \"FLL\", \"IAD\",…\n$ air_time       &lt;dbl&gt; 227, 227, 160, 183, 116, 150, 158, 53, 140, 138, 149, 1…\n$ distance       &lt;dbl&gt; 1400, 1416, 1089, 1576, 762, 719, 1065, 229, 944, 733, …\n$ hour           &lt;dbl&gt; 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6…\n$ minute         &lt;dbl&gt; 15, 29, 40, 45, 0, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59, 0…\n$ time_hour      &lt;dttm&gt; 2013-01-01 05:00:00, 2013-01-01 05:00:00, 2013-01-01 0…"
  },
  {
    "objectID": "PracticalThree.html#display-the-flights-dataset-in-an-alternative-format-to-simply-printing-it",
    "href": "PracticalThree.html#display-the-flights-dataset-in-an-alternative-format-to-simply-printing-it",
    "title": "Practical Three",
    "section": "",
    "text": "library(nycflights13)\n\nWarning: package 'nycflights13' was built under R version 4.3.3\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.3.3\n\n\nWarning: package 'forcats' was built under R version 4.3.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# using the flights dataset\nglimpse(flights)\n\nRows: 336,776\nColumns: 19\n$ year           &lt;int&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2…\n$ month          &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ day            &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ dep_time       &lt;int&gt; 517, 533, 542, 544, 554, 554, 555, 557, 557, 558, 558, …\n$ sched_dep_time &lt;int&gt; 515, 529, 540, 545, 600, 558, 600, 600, 600, 600, 600, …\n$ dep_delay      &lt;dbl&gt; 2, 4, 2, -1, -6, -4, -5, -3, -3, -2, -2, -2, -2, -2, -1…\n$ arr_time       &lt;int&gt; 830, 850, 923, 1004, 812, 740, 913, 709, 838, 753, 849,…\n$ sched_arr_time &lt;int&gt; 819, 830, 850, 1022, 837, 728, 854, 723, 846, 745, 851,…\n$ arr_delay      &lt;dbl&gt; 11, 20, 33, -18, -25, 12, 19, -14, -8, 8, -2, -3, 7, -1…\n$ carrier        &lt;chr&gt; \"UA\", \"UA\", \"AA\", \"B6\", \"DL\", \"UA\", \"B6\", \"EV\", \"B6\", \"…\n$ flight         &lt;int&gt; 1545, 1714, 1141, 725, 461, 1696, 507, 5708, 79, 301, 4…\n$ tailnum        &lt;chr&gt; \"N14228\", \"N24211\", \"N619AA\", \"N804JB\", \"N668DN\", \"N394…\n$ origin         &lt;chr&gt; \"EWR\", \"LGA\", \"JFK\", \"JFK\", \"LGA\", \"EWR\", \"EWR\", \"LGA\",…\n$ dest           &lt;chr&gt; \"IAH\", \"IAH\", \"MIA\", \"BQN\", \"ATL\", \"ORD\", \"FLL\", \"IAD\",…\n$ air_time       &lt;dbl&gt; 227, 227, 160, 183, 116, 150, 158, 53, 140, 138, 149, 1…\n$ distance       &lt;dbl&gt; 1400, 1416, 1089, 1576, 762, 719, 1065, 229, 944, 733, …\n$ hour           &lt;dbl&gt; 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6…\n$ minute         &lt;dbl&gt; 15, 29, 40, 45, 0, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59, 0…\n$ time_hour      &lt;dttm&gt; 2013-01-01 05:00:00, 2013-01-01 05:00:00, 2013-01-01 0…"
  },
  {
    "objectID": "PracticalThree.html#rewrite-the-following-code-using-dplyr-and-the-pipe.",
    "href": "PracticalThree.html#rewrite-the-following-code-using-dplyr-and-the-pipe.",
    "title": "Practical Three",
    "section": "2. Rewrite the following code using dplyr and the pipe.",
    "text": "2. Rewrite the following code using dplyr and the pipe.\nThe code that needs to be re-written:\n\nflight1 &lt;- flights[flights$month == 1, ]\ncarrier_vec &lt;- unique(flight1$carrier)\ncarrier_dist_vec_mean &lt;- numeric(length(carrier_vec))\ncarrier_dist_vec_sd &lt;- numeric(length(carrier_vec))\nfor (i in seq_along(carrier_vec)) {\n  carrier_dist_vec_mean[i] &lt;- mean(\n    flight1$distance[flight1$carrier == carrier_vec[i]]\n   )\n  carrier_dist_vec_sd[i] &lt;- sd(\n    flight1$distance[flight1$carrier == carrier_vec[i]]\n  )\n}\ndist_tbl &lt;- tibble(\n  carrier = carrier_vec,\n  mean_distance = carrier_dist_vec_mean,\n  sd_distance = carrier_dist_vec_sd\n)\ndist_tbl[order(dist_tbl$mean_distance), ]\n\n# A tibble: 16 × 3\n   carrier mean_distance sd_distance\n   &lt;chr&gt;           &lt;dbl&gt;       &lt;dbl&gt;\n 1 YV               229          0  \n 2 9E               476.       334. \n 3 EV               522.       294. \n 4 US               536.       553. \n 5 MQ               566.       223. \n 6 FL               691.       142. \n 7 OO               733         NA  \n 8 WN               942.       496. \n 9 B6              1062.       681. \n10 DL              1220.       644. \n11 AA              1350.       626. \n12 UA              1462.       778. \n13 F9              1620          0  \n14 AS              2402          0  \n15 VX              2495.        98.2\n16 HA              4983          0  \n\n\nThe re-written code:\n\ndist_tbl &lt;- flights |&gt;\n  filter(month == 1) |&gt;\n  group_by(carrier) |&gt;\n  summarise(mean_distance = mean(distance), sd_distance = sd(distance)) |&gt;\n  arrange(mean_distance)\ndist_tbl\n\n# A tibble: 16 × 3\n   carrier mean_distance sd_distance\n   &lt;chr&gt;           &lt;dbl&gt;       &lt;dbl&gt;\n 1 YV               229          0  \n 2 9E               476.       334. \n 3 EV               522.       294. \n 4 US               536.       553. \n 5 MQ               566.       223. \n 6 FL               691.       142. \n 7 OO               733         NA  \n 8 WN               942.       496. \n 9 B6              1062.       681. \n10 DL              1220.       644. \n11 AA              1350.       626. \n12 UA              1462.       778. \n13 F9              1620          0  \n14 AS              2402          0  \n15 VX              2495.        98.2\n16 HA              4983          0"
  },
  {
    "objectID": "PracticalThree.html#explain-why-the-standard-deviation-in-na-for-one-carrier-and-why-it-is-0-for-others",
    "href": "PracticalThree.html#explain-why-the-standard-deviation-in-na-for-one-carrier-and-why-it-is-0-for-others",
    "title": "Practical Three",
    "section": "3. Explain why the standard deviation in NA for one carrier and why it is 0 for others?",
    "text": "3. Explain why the standard deviation in NA for one carrier and why it is 0 for others?\nThe standard deviation is NA becasue there is only 1 record where Carrier OO has month = 1.\n\nflights |&gt;\n  filter(carrier == \"OO\" & month == 1) |&gt;\n  select(carrier, distance)\n\n# A tibble: 1 × 2\n  carrier distance\n  &lt;chr&gt;      &lt;dbl&gt;\n1 OO           733\n\n\nThis means that when the standard deviation is calulated from the sample, the sum of squares of the distance is divided by n-1, however since n=1, the denominator becomes 0 and therefore the standard deviation result is NA.\nThe standard deviation is 0 for others because the the values are the same as the mean in the dataset. Below is an example of one of the rows that have a standard deviation of 0, looked at in more depth.\n\nflights |&gt;\n  filter(carrier == \"YV\" & month == 1) |&gt;\n  select(carrier, distance)\n\n# A tibble: 46 × 2\n   carrier distance\n   &lt;chr&gt;      &lt;dbl&gt;\n 1 YV           229\n 2 YV           229\n 3 YV           229\n 4 YV           229\n 5 YV           229\n 6 YV           229\n 7 YV           229\n 8 YV           229\n 9 YV           229\n10 YV           229\n# ℹ 36 more rows"
  },
  {
    "objectID": "PracticalThree.html#using-tidyr-and-dplyr-where-appropriate-construct-a-dataframe-where-carriers-are-along-the-columns-and-the-rows-are-the-avg-dep_delays-flown-by-each-character-in-a-month",
    "href": "PracticalThree.html#using-tidyr-and-dplyr-where-appropriate-construct-a-dataframe-where-carriers-are-along-the-columns-and-the-rows-are-the-avg-dep_delays-flown-by-each-character-in-a-month",
    "title": "Practical Three",
    "section": "4. Using tidyr and dplyr where appropriate, construct a dataframe where carriers are along the columns and the rows are the avg dep_delays flown by each character in a month",
    "text": "4. Using tidyr and dplyr where appropriate, construct a dataframe where carriers are along the columns and the rows are the avg dep_delays flown by each character in a month\n\nflights |&gt; \n  group_by(month, carrier) |&gt;\n  summarise(avg_dep_delay = mean(dep_delay, na.rm = TRUE)) |&gt;\n  pivot_wider(names_from = carrier, values_from = avg_dep_delay)\n\n`summarise()` has grouped output by 'month'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 12 × 17\n# Groups:   month [12]\n   month  `9E`    AA     AS    B6    DL    EV    F9    FL    HA    MQ    OO\n   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     1 16.9   6.93  7.35   9.49  3.85 24.2  10     1.97 54.4   6.49 67   \n 2     2 16.5   8.28  0.722 13.8   5.54 21.5  29.8   5.18 17.4   8.09 NA   \n 3     3 13.4   8.70  8.42  14.2   9.93 26.2  16.8  17.3   1.16  7.19 NA   \n 4     4 13.6  11.7  11.3   15.2   8.17 22.8  24.6  13.1  -2.1  13.7  NA   \n 5     5 22.7   9.66  6.77   9.78  9.74 20.2  35.9  19.2  -1.45 13.9  NA   \n 6     6 29.0  14.6  13.1   20.4  18.7  25.5  29.4  38.8   1.47 20.8  61   \n 7     7 31.4  12.1   2.42  24.9  20.6  26.5  31.8  41.2  -1.71 20.7  NA   \n 8     8 17.3   7.17  2.87  15.7   9.85 16.3  22.2  23.4   1.68 10.1  64   \n 9     9  7.75  5.69 -4.52   6.63  5.53  8.24  8.26 16.9  -5.44  5.35 -4.94\n10    10  9.33  3.00  0.677  2.96  3.42 13.4   9.70 13.7  -5.10  4.48 NA   \n11    11  7.56  3.10  3.08   3.52  2.85  9.83 13.5  16.9  -5.44  3.28  0.8 \n12    12 19.8  11.7  18.0   17.0  10.8  27.9  13.1  26.1  -3.14 12.7  NA   \n# ℹ 5 more variables: UA &lt;dbl&gt;, US &lt;dbl&gt;, VX &lt;dbl&gt;, WN &lt;dbl&gt;, YV &lt;dbl&gt;"
  },
  {
    "objectID": "PracticalThree.html#calculate-the-proportion-of-flights-that-were-delayed-but-arrived-on-or-before-time.",
    "href": "PracticalThree.html#calculate-the-proportion-of-flights-that-were-delayed-but-arrived-on-or-before-time.",
    "title": "Practical Three",
    "section": "5. Calculate the proportion of flights that were delayed but arrived on or before time.",
    "text": "5. Calculate the proportion of flights that were delayed but arrived on or before time.\n\n# creates a table of all the flights here dep_delay is bigger than 0 and where those flights arrived on or before time\nflights_delayed &lt;- flights |&gt; \n  filter(dep_delay &gt; 0 & arr_delay &lt;=0)\n\n# calculates the proportionof flights\nnrow(flights_delayed)/ nrow(flights)\n\n[1] 0.1052391"
  },
  {
    "objectID": "PracticalThree.html#using-the-airlines-and-the-flights-data-set-do-the-following-and-show-the-output",
    "href": "PracticalThree.html#using-the-airlines-and-the-flights-data-set-do-the-following-and-show-the-output",
    "title": "Practical Three",
    "section": "6. Using the airlines and the flights data set, do the following and show the output:",
    "text": "6. Using the airlines and the flights data set, do the following and show the output:\n\n6.1 Identify routes that more than 1 airline flies\n\nairlines\n\n# A tibble: 16 × 2\n   carrier name                       \n   &lt;chr&gt;   &lt;chr&gt;                      \n 1 9E      Endeavor Air Inc.          \n 2 AA      American Airlines Inc.     \n 3 AS      Alaska Airlines Inc.       \n 4 B6      JetBlue Airways            \n 5 DL      Delta Air Lines Inc.       \n 6 EV      ExpressJet Airlines Inc.   \n 7 F9      Frontier Airlines Inc.     \n 8 FL      AirTran Airways Corporation\n 9 HA      Hawaiian Airlines Inc.     \n10 MQ      Envoy Air                  \n11 OO      SkyWest Airlines Inc.      \n12 UA      United Air Lines Inc.      \n13 US      US Airways Inc.            \n14 VX      Virgin America             \n15 WN      Southwest Airlines Co.     \n16 YV      Mesa Airlines Inc.         \n\nglimpse(flights)\n\nRows: 336,776\nColumns: 19\n$ year           &lt;int&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2…\n$ month          &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ day            &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ dep_time       &lt;int&gt; 517, 533, 542, 544, 554, 554, 555, 557, 557, 558, 558, …\n$ sched_dep_time &lt;int&gt; 515, 529, 540, 545, 600, 558, 600, 600, 600, 600, 600, …\n$ dep_delay      &lt;dbl&gt; 2, 4, 2, -1, -6, -4, -5, -3, -3, -2, -2, -2, -2, -2, -1…\n$ arr_time       &lt;int&gt; 830, 850, 923, 1004, 812, 740, 913, 709, 838, 753, 849,…\n$ sched_arr_time &lt;int&gt; 819, 830, 850, 1022, 837, 728, 854, 723, 846, 745, 851,…\n$ arr_delay      &lt;dbl&gt; 11, 20, 33, -18, -25, 12, 19, -14, -8, 8, -2, -3, 7, -1…\n$ carrier        &lt;chr&gt; \"UA\", \"UA\", \"AA\", \"B6\", \"DL\", \"UA\", \"B6\", \"EV\", \"B6\", \"…\n$ flight         &lt;int&gt; 1545, 1714, 1141, 725, 461, 1696, 507, 5708, 79, 301, 4…\n$ tailnum        &lt;chr&gt; \"N14228\", \"N24211\", \"N619AA\", \"N804JB\", \"N668DN\", \"N394…\n$ origin         &lt;chr&gt; \"EWR\", \"LGA\", \"JFK\", \"JFK\", \"LGA\", \"EWR\", \"EWR\", \"LGA\",…\n$ dest           &lt;chr&gt; \"IAH\", \"IAH\", \"MIA\", \"BQN\", \"ATL\", \"ORD\", \"FLL\", \"IAD\",…\n$ air_time       &lt;dbl&gt; 227, 227, 160, 183, 116, 150, 158, 53, 140, 138, 149, 1…\n$ distance       &lt;dbl&gt; 1400, 1416, 1089, 1576, 762, 719, 1065, 229, 944, 733, …\n$ hour           &lt;dbl&gt; 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6…\n$ minute         &lt;dbl&gt; 15, 29, 40, 45, 0, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59, 0…\n$ time_hour      &lt;dttm&gt; 2013-01-01 05:00:00, 2013-01-01 05:00:00, 2013-01-01 0…\n\ncommon_routes &lt;- flights |&gt;\n  group_by(origin, dest) |&gt;\n  summarise(num_airlines = n_distinct(carrier)) |&gt;\n  filter(num_airlines &gt;1)\n\n`summarise()` has grouped output by 'origin'. You can override using the\n`.groups` argument.\n\ncommon_routes\n\n# A tibble: 128 × 3\n# Groups:   origin [3]\n   origin dest  num_airlines\n   &lt;chr&gt;  &lt;chr&gt;        &lt;int&gt;\n 1 EWR    ATL              4\n 2 EWR    AUS              2\n 3 EWR    BDL              2\n 4 EWR    BNA              2\n 5 EWR    BOS              3\n 6 EWR    BWI              2\n 7 EWR    CHS              2\n 8 EWR    CLE              2\n 9 EWR    CLT              3\n10 EWR    CVG              2\n# ℹ 118 more rows\n\n\n\n\n6.2 For each of those routes, calculate the avg arrival delay for each airline\n\navg_arrival_delay &lt;-  flights |&gt;\n  inner_join(common_routes, by = c(\"origin\", \"dest\")) |&gt;\n  group_by(origin, dest, carrier) |&gt;\n  summarise(avg_arr_delay = mean(arr_delay, na.rm = TRUE))\n\n`summarise()` has grouped output by 'origin', 'dest'. You can override using\nthe `.groups` argument.\n\navg_arrival_delay\n\n# A tibble: 343 × 4\n# Groups:   origin, dest [128]\n   origin dest  carrier avg_arr_delay\n   &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;           &lt;dbl&gt;\n 1 EWR    ATL   9E              -6.25\n 2 EWR    ATL   DL              10.0 \n 3 EWR    ATL   EV              19.5 \n 4 EWR    ATL   UA              10.5 \n 5 EWR    AUS   UA               4.28\n 6 EWR    AUS   WN             -11.2 \n 7 EWR    BDL   EV               6.78\n 8 EWR    BDL   UA              22.6 \n 9 EWR    BNA   EV              17.7 \n10 EWR    BNA   WN              -2.13\n# ℹ 333 more rows\n\n#Find the names of these airlines\navg_airline_arr_delay &lt;- avg_arrival_delay |&gt;\n  inner_join(airlines, by = \"carrier\") |&gt;\n  select(origin, dest, name, avg_arr_delay)\navg_airline_arr_delay\n\n# A tibble: 343 × 4\n# Groups:   origin, dest [128]\n   origin dest  name                     avg_arr_delay\n   &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;                            &lt;dbl&gt;\n 1 EWR    ATL   Endeavor Air Inc.                -6.25\n 2 EWR    ATL   Delta Air Lines Inc.             10.0 \n 3 EWR    ATL   ExpressJet Airlines Inc.         19.5 \n 4 EWR    ATL   United Air Lines Inc.            10.5 \n 5 EWR    AUS   United Air Lines Inc.             4.28\n 6 EWR    AUS   Southwest Airlines Co.          -11.2 \n 7 EWR    BDL   ExpressJet Airlines Inc.          6.78\n 8 EWR    BDL   United Air Lines Inc.            22.6 \n 9 EWR    BNA   ExpressJet Airlines Inc.         17.7 \n10 EWR    BNA   Southwest Airlines Co.           -2.13\n# ℹ 333 more rows\n\n\n\n\n6.3 For each of those routes, identify the airline with the worst and best average arrival delay\n\nbest_worst_airlines &lt;-  avg_airline_arr_delay |&gt;\n  group_by(origin, dest) |&gt;\n  summarise( best_airline = name[which.min(avg_arr_delay)],\n             best_delay = min(avg_arr_delay),\n             worst_airline = name[which.max(avg_arr_delay)],\n             worst_delay = max(avg_arr_delay))\n\n`summarise()` has grouped output by 'origin'. You can override using the\n`.groups` argument.\n\nbest_worst_airlines\n\n# A tibble: 128 × 6\n# Groups:   origin [3]\n   origin dest  best_airline             best_delay worst_airline    worst_delay\n   &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;                         &lt;dbl&gt; &lt;chr&gt;                  &lt;dbl&gt;\n 1 EWR    ATL   Endeavor Air Inc.            -6.25  ExpressJet Airl…       19.5 \n 2 EWR    AUS   Southwest Airlines Co.      -11.2   United Air Line…        4.28\n 3 EWR    BDL   ExpressJet Airlines Inc.      6.78  United Air Line…       22.6 \n 4 EWR    BNA   Southwest Airlines Co.       -2.13  ExpressJet Airl…       17.7 \n 5 EWR    BOS   ExpressJet Airlines Inc.     -4.01  JetBlue Airways         6.87\n 6 EWR    BWI   Southwest Airlines Co.        5.95  ExpressJet Airl…       20.1 \n 7 EWR    CHS   United Air Lines Inc.       -14     ExpressJet Airl…       16.2 \n 8 EWR    CLE   ExpressJet Airlines Inc.     -3.71  United Air Line…        5.97\n 9 EWR    CLT   US Airways Inc.               0.920 ExpressJet Airl…       20.5 \n10 EWR    CVG   Endeavor Air Inc.             1.40  ExpressJet Airl…       21.2 \n# ℹ 118 more rows\n\n\n\n\n6.4 Identify the route with the biggest difference between the best and worst performing airlines\n\nmax_difference_route &lt;- best_worst_airlines |&gt;\n  mutate(arr_delay_diff = worst_delay - best_delay) |&gt;\n  arrange(desc(arr_delay_diff)) \n  \nhead(max_difference_route, 1)\n\n# A tibble: 1 × 7\n# Groups:   origin [1]\n  origin dest  best_airline  best_delay worst_airline worst_delay arr_delay_diff\n  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;          &lt;dbl&gt;\n1 JFK    ATL   Endeavor Air…       1.40 ExpressJet A…         128           127.\n\n\n\n\n6.5 Determine the reason for the difference\n\nflights |&gt;\n  filter(origin == max_difference_route$origin, \n         dest == max_difference_route$dest) |&gt;\n  group_by(carrier) |&gt;\n  summarise(num_flights = n()) |&gt;\n  inner_join(airlines, by = \"carrier\") |&gt;\n  select(name, num_flights)\n\nWarning: There were 2 warnings in `filter()`.\nThe first warning was:\nℹ In argument: `origin == max_difference_route$origin`.\nCaused by warning in `origin == max_difference_route$origin`:\n! longer object length is not a multiple of shorter object length\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\n\n# A tibble: 15 × 2\n   name                        num_flights\n   &lt;chr&gt;                             &lt;int&gt;\n 1 Endeavor Air Inc.                   122\n 2 American Airlines Inc.              254\n 3 Alaska Airlines Inc.                  7\n 4 JetBlue Airways                     345\n 5 Delta Air Lines Inc.                423\n 6 ExpressJet Airlines Inc.            242\n 7 Frontier Airlines Inc.                6\n 8 AirTran Airways Corporation          19\n 9 Envoy Air                           201\n10 SkyWest Airlines Inc.                 2\n11 United Air Lines Inc.               347\n12 US Airways Inc.                      98\n13 Virgin America                       47\n14 Southwest Airlines Co.               43\n15 Mesa Airlines Inc.                    5\n\n\nAs seen from this output, Eandeavor Air Inc. (best average arrival delay) flies 122 on this route whilst ExpressJet Airlines Inc. (worst average arrival delay) flies 242 times on this route. Some possible reason why they have the greatest difference, could be because Eandeavor Air Inc. might have the fancier and wealthier airline so they could have better engines that allow the plane to fly faster, r they have better ground organisation that plan the schedules for the runways, and they could have better navigation systems to allow them to find the quickest path to the destination without compromising health and safety."
  },
  {
    "objectID": "PracticalThree.html#identify-all-columns-with-missing-entries-typos-and-other-inconsistencies-in-the-dataset",
    "href": "PracticalThree.html#identify-all-columns-with-missing-entries-typos-and-other-inconsistencies-in-the-dataset",
    "title": "Practical Three",
    "section": "7. Identify all columns with missing entries, typos and other inconsistencies in the dataset",
    "text": "7. Identify all columns with missing entries, typos and other inconsistencies in the dataset\n\n# The copied and inconsistent and flawed dataset:\ndataset &lt;-  structure(list(id = c(\"id_1\", \"id_2\", \"id_3\", \"id_4\", \"id_5\", \n\"id_6\", \"id_7\", \"id_8\", \"id_9\", \"id_10\", \"id_11\", \"id_12\", \"id_13\", \n\"id_14\", \"id_15\", \"id_16\", \"id_17\", \"id_18\", \"id_19\", \"id_20\", \n\"id_21\", \"id_22\", \"id_23\", \"id_24\", \"id_25\", \"id_26\", \"id_27\", \n\"id_28\", \"id_29\", \"id_30\", \"id_31\", \"id_32\", \"id_33\", \"id_34\", \n\"id_35\", \"id_36\", \"id_37\", \"id_38\", \"id_39\", \"id_40\", \"id_41\", \n\"id_42\", \"id_43\", \"id_44\", \"id_45\", \"id_46\", \"id_47\", \"id_48\", \n\"id_49\", \"id_50\"), age = c(50L, 34L, 70L, 33L, 22L, 61L, 69L, \n73L, 62L, 56L, 71L, 33L, 73L, 44L, 45L, 46L, 24L, 70L, 46L, 76L, \n47L, 76L, 28L, 48L, 54L, 27L, 45L, 26L, 61L, 28L, 38L, 55L, 33L, \n36L, 62L, 58L, 72L, 31L, 34L, 51L, 61L, 64L, 26L, 28L, 60L, 29L, \n42L, 46L, 79L, 72L), gender = c(\"male\", \"male\", \"male\", \"female\", \n\"female\", \"male\", \"female\", \"male\", \"male\", \"female\", \"female\", \n\"male\", \"male\", \"female\", \"male\", \"male\", \"male\", \"male\", \"female\", \n\"male\", \"male\", \"male\", \"male\", \"female\", \"femal\", \"male\", \"female\", \n\"female\", \"female\", \"female\", \"male\", \"female\", \"female\", \"female\", \n\"male\", \"male\", \"female\", \"male\", \"female\", \"female\", \"male\", \n\"female\", \"female\", \"male\", \"male\", \"female\", \"male\", \"male\", \n\"male\", \"female\"), height = c(174.4, 197.7, 174.1, 194.5, NA, \n180.4, 170.5, 157.4, 196.8, 165.1, 153, 197.4, 186, 157.1, 177.5, \n197.7, 179.3, 170.2, 182.4, NA, 165.4, 161, 168.5, 199.2, 157.7, \n154.6, 157.1, 184.5, 181, 194.6, 183.6, 186.9, 176.1, 183, 191.1, \n189.3, 199, 172, 165.6, 170.5, 150.5, 159.2, 192.1, 161.6, 162, \n153.8, 162.3, 186.6, 192.4, 174.9), weight = c(69.4, 62.3, 55.6, \n69.5, 78.6, 60.8, 72.2, 60.9, 75.1, 67.7, 82.5, 68.7, 67.8, 76.7, \n87, 61.1, 70.6, 63.3, 81.5, 59.2, 93.2, 87.3, 83.4, 80.9, 68.6, \n76.5, 93.7, 79.1, 92, 65.6, 85.4, 63.3, 79.7, 74.1, 63.3, 78.2, \n95.7, 95.1, 63.7, 66.1, 99.3, 81, 96.9, 73.3, 70.3, 83, 57.6, \n78.6, 61.9, 98.1), blood_type = c(\"O\", \"A\", \"O\", \"O\", \"B\", \"AB\", \n\"O\", \"O\", \"O\", \"AB\", \"A\", \"O\", \"O\", \"O\", \"B\", \"A\", \"B\", \"AB\", \n\"O\", \"AB\", \"A\", \"AB\", \"O\", \"B\", \"A\", \"A\", \"B\", \"AB\", \"A\", \"B\", \n\"B\", \"A\", \"O\", \"O\", \"O\", \"B\", \"O\", \"A\", \"A\", \"B\", \"A\", \"O\", \"AB\", \n\"A\", \"A\", \"O\", \"O\", \"B\", \"A\", \"O\"), disease_status = c(\"diseased\", \n\"healthy\", \"healthy\", \"healthy\", \"healthy\", \"healthy\", \"diseased\", \n\"healthy\", \"diseased\", \"Healthy\", \"diseased\", \"healthy\", \"diseased\", \n\"healthy\", \"diseased\", \"healthy\", \"healthy\", \"healthy\", \"healthy\", \n\"healthy\", \"healthy\", \"diseased\", \"healthy\", \"diseased\", \"healthy\", \n\"healthy\", \"healthy\", \"healthy\", \"diseased\", \"diseased\", \"healthy\", \n\"healthy\", \"healthy\", \"diseased\", \"diseased\", \"diseased\", \"healthy\", \n\"diseased\", \"healthy\", \"healthy\", \"healthy\", \"healthy\", \"healthy\", \n\"diseased\", \"diseased\", \"diseased\", \"healthy\", \"healthy\", \"diseased\", \n\"diseased\"), cholesterol = c(228, 223, 213, 198, 166, 151, 195, \n199, 189, 196, 221, 156, 185, 230, 234, 174, 185, 236, 235, 180, \n165, 220, 160, 153, 250, 153, 184, 242, 212, 179, 224, 233, 181, \n199, 220, 214, 214, 248, 191, 162, 203, 173, 199, 187, 248, 189, \n173, 212, 164, 247), glucose = c(96, 78, 101, 119, 103, 91, 86, \nNA, 77, 80, 115, 85, 88, 109, NA, 71, 90, 94, 91, 87, 113, 93, \n97, 118, 109, 80, 85, 119, 99, 108, 89, 108, 97, 116, 79, 84, \n75, 81, 119, NA, 106, 109, 75, 82, 84, 75, 76, 120, 119, 77), \n    smoker = c(\"yes\", \"yes\", \"yes\", \"yes\", \"no\", \"yes\", \"no\", \n    \"yes\", \"no\", \"no\", \"no\", \"no\", \"no\", \"yes\", \"no\", \"yes\", \n    \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"no\", \n    \"no\", \"yes\", \"yes\", \"yes\", \"no\", \"no\", \"yes\", \"no\", \"yes\", \n    \"no\", \"yes\", \"no\", \"yes\", \"yes\", \"yes\", \"no\", \"no\", \"yes\", \n    \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"yes\"), exercise = c(\"occasional\", \n    \"regular\", \"occasional\", \"regular\", \"none\", \"occasional\", \n    \"regular\", \"none\", \"occasional\", \"none\", \"occasional\", \"none\", \n    \"none\", \"regular\", \"occasional\", \"none\", \"regular\", \"regular\", \n    \"none\", \"occasional\", \"none\", \"occasional\", \"occasional\", \n    \"occasional\", \"regular\", \"occasional\", \"regular\", \"regular\", \n    \"regular\", \"occasional\", \"occasional\", \"none\", \"none\", \"regular\", \n    \"occasional\", \"occasional\", \"none\", \"none\", \"none\", \"none\", \n    \"occasional\", \"regular\", \"regular\", \"none\", \"regular\", \"occasional\", \n    \"occasional\", \"none\", \"occasional\", \"regular\"), income = c(84820L, \n    81547L, 22588L, 72490L, 74533L, 25338L, 41469L, 57315L, 63629L, \n    88662L, 62615L, 56261L, 58499L, 82232L, 77584L, 77275L, 38468L, \n    54510L, 91326L, 78611L, 31402L, 29586L, 21441L, 58269L, 84173L, \n    88295L, 37940L, 43750L, 69750L, 92356L, 82518L, 91455L, 68866L, \n    51178L, 68275L, 27689L, 35418L, 81318L, 62405L, 86851L, 25654L, \n    47553L, 74474L, 51409L, 22607L, 55360L, 96351L, 21516L, 41927L, \n    55810L), education = c(\"master\", \"bachelor\", \"PhD\", \"master\", \n    \"bachelor\", \"highschool\", \"PhD\", \"highschool\", \"PhD\", \"PhD\", \n    \"bachelor\", \"highschool\", \"master\", \"bachelor\", \"PhD\", \"PhD\", \n    \"PhD\", \"bachelor\", \"master\", \"highschool\", \"PhD\", \"highschool\", \n    \"bachelor\", \"master\", \"highschool\", \"highschool\", \"master\", \n    \"master\", \"bachelor\", \"PhD\", \"highschool\", \"PhD\", \"master\", \n    \"master\", \"master\", \"PhD\", \"highschool\", \"master\", \"master\", \n    \"highschool\", \"bachelor\", \"highschool\", \"bachelor\", \"PhD\", \n    \"bachelor\", \"highschool\", \"master\", \"highschool\", \"bachelor\", \n    \"bachelor\"), region = c(\"North\", \"South\", \"North\", \"West\", \n    \"North\", \"West\", \"South\", \"South\", \"West\", \"South\", \"West\", \n    \"South\", \"West\", \"East\", \"North\", \"West\", \"North\", \"North\", \n    \"West\", \"North\", \"East\", \"West\", \"South\", \"North\", \"North\", \n    \"East\", \"East\", \"North\", \"North\", \"West\", \"South\", \"West\", \n    \"West\", \"East\", \"West\", \"North\", \"West\", \"North\", \"East\", \n    \"North\", \"West\", \"South\", \"South\", \"East\", \"North\", \"West\", \n    \"West\", \"East\", \"North\", \"East\"), marital_status = c(\"divorced\", \n    \"single\", \"divorced\", \"divorced\", \"divorced\", \"divorced\", \n    \"divorced\", \"married\", \"divorced\", \"married\", \"divorced\", \n    \"widowed\", \"married\", \"single\", \"widowed\", \"widowed\", \"single\", \n    \"divorced\", \"widowed\", \"widowed\", \"single\", \"married\", \"single\", \n    \"married\", \"widowed\", \"married\", \"single\", \"single\", \"widowed\", \n    \"married\", \"widowed\", \"divorced\", \"single\", \"married\", \"single\", \n    \"widowed\", \"widowed\", \"married\", \"widowed\", \"divorced\", \"married\", \n    \"married\", \"divorced\", \"single\", \"married\", \"widowed\", \"divorced\", \n    \"divorced\", \"single\", \"divorced\")), row.names = c(NA, -50L\n), class = c(\"tbl_df\", \"tbl\", \"data.frame\"))\n\ndataset\n\n# A tibble: 50 × 15\n   id      age gender height weight blood_type disease_status cholesterol\n   &lt;chr&gt; &lt;int&gt; &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;                &lt;dbl&gt;\n 1 id_1     50 male     174.   69.4 O          diseased               228\n 2 id_2     34 male     198.   62.3 A          healthy                223\n 3 id_3     70 male     174.   55.6 O          healthy                213\n 4 id_4     33 female   194.   69.5 O          healthy                198\n 5 id_5     22 female    NA    78.6 B          healthy                166\n 6 id_6     61 male     180.   60.8 AB         healthy                151\n 7 id_7     69 female   170.   72.2 O          diseased               195\n 8 id_8     73 male     157.   60.9 O          healthy                199\n 9 id_9     62 male     197.   75.1 O          diseased               189\n10 id_10    56 female   165.   67.7 AB         Healthy                196\n# ℹ 40 more rows\n# ℹ 7 more variables: glucose &lt;dbl&gt;, smoker &lt;chr&gt;, exercise &lt;chr&gt;,\n#   income &lt;int&gt;, education &lt;chr&gt;, region &lt;chr&gt;, marital_status &lt;chr&gt;\n\n#identify the columns with missing values\nmissing_val &lt;- colSums(is.na(dataset)) \nmissing_val &lt;- missing_val[missing_val &gt; 0]\n# the number of missing values in each column is: \nmissing_val\n\n height glucose \n      2       3 \n\n#identify inconsistencies and typos\ncategorical_var &lt;- c(\"gender\", \"disease_status\")\ntypo_check &lt;- lapply(dataset[categorical_var], unique)\n# the typos and inconsistencies\ntypo_check\n\n$gender\n[1] \"male\"   \"female\" \"femal\" \n\n$disease_status\n[1] \"diseased\" \"healthy\"  \"Healthy\" \n\n\nFor an improvement suggestion: both columns, gender and disease_status can be tured into binary variables since in this dataset, both columns only have 2 different observed options for each."
  }
]